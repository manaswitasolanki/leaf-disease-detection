{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manaswitasolanki/leaf-disease-detection/blob/main/plant_disease_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC8Xx8tAQHS6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hdQhgTJQM-t"
      },
      "source": [
        "**PLANT DISEASE PREDICTION USING IMAGES OF HEALTHY AND UNHEALTHY LEAVES**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "DATASET : '*plant_village*' from Github\n",
        "         ( link:https://github.com/spMohanty/PlantVillage-Dataset)\n",
        "This dataset has more than 50,000 images of plant leaves divided into 38 categories. \n",
        "\n",
        "To classify the images we will use a Convolution Neural Network.\n",
        "(It basically contains layers just like an ANN but it uses techniques like applyling filters , max pooling ( reducing the input layer size) , flattening etc.) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNepg8nCVM1k"
      },
      "source": [
        "The PlantVillage dataset consists of 54303 healthy and unhealthy leaf images divided into 38 categories by species and disease.\n",
        "\n",
        "First we will load the dataset from Github \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IOx0o2rn_049"
      },
      "outputs": [],
      "source": [
        "#importing the libraries we need to download the dataset\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ljnKr4NHA5Jq",
        "outputId": "4412acce-88f8-42af-cc73-89d23d0bf14b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-03 18:12:01--  https://github.com/spMohanty/PlantVillage-Dataset/archive/refs/heads/master.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/spMohanty/PlantVillage-Dataset/zip/refs/heads/master [following]\n",
            "--2022-08-03 18:12:01--  https://codeload.github.com/spMohanty/PlantVillage-Dataset/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.113.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.113.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/plant-village.zip’\n",
            "\n",
            "/tmp/plant-village.     [ <=>                ]   2.33G  33.2MB/s    in 82s     \n",
            "\n",
            "2022-08-03 18:13:24 (29.2 MB/s) - ‘/tmp/plant-village.zip’ saved [2503721860]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#downloading dataset from github  repository we will save it in tmp folder\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/spMohanty/PlantVillage-Dataset/archive/refs/heads/master.zip\" \\\n",
        "    -O \"/tmp/plant-village.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('/tmp/plant-village.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "YUU7lSlBunqP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After discovering about ways of implementing CNN , I found Keras very interesting and easy :D but after several errors I realized that unlike other techniques, Keras only works if your input is in the form of a numpy array \n",
        "It took me a very long time to pre-process the data because of my beginner knowledge in python."
      ],
      "metadata": {
        "id": "9asNgpMgJixf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2    #we will use it to preprocess the dataset\n",
        "import numpy as np   #used for mathematical functions like matrices"
      ],
      "metadata": {
        "id": "dLk1H-MOpbv1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will set the height and width of the image to 128 . CNN works better if the size of the input images are the same (we can also apply padding but I felt that will use additional memory)\n",
        "The number of channels are nothing but the depth of the image - I am using RGB which has a depth of 3 (greyscale has 1 etc.)"
      ],
      "metadata": {
        "id": "6s__OPEnKQ2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows=128 #no.of rows in an image\n",
        "img_cols=128  #no.of columns in an image\n",
        "num_channel=3 # no. of channels (rgb)"
      ],
      "metadata": {
        "id": "kYOJs_ADqOoh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially found it difficult to know where the files are located on colab but I soon discovered about the os library and now can directly select folders using paths"
      ],
      "metadata": {
        "id": "2U_ED8rkLMVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_list = os.listdir('/tmp/PlantVillage-Dataset-master/raw/color') #the path where the dataset is stored"
      ],
      "metadata": {
        "id": "WI10A5QprCbR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we know that the plant village dataset has 38 categories we will specify the number of classes as 38\n",
        "We will use a dictionary to assign values to the different classes\n",
        "We will create empty numpy arrays for the images and the labels"
      ],
      "metadata": {
        "id": "pX8F3Z_BLgJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 38\n",
        "labels_name={'Apple___Apple_scab':0,\n",
        "             'Apple___Black_rot':1,\n",
        "             'Apple___Cedar_apple_rust':2,\n",
        "             'Apple___healthy':3,\n",
        "             'Blueberry___healthy':4,\n",
        "             'Cherry_(including_sour)___Powdery_mildew':5,\n",
        "             'Cherry_(including_sour)___healthy':6,\n",
        "             'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot':7,\n",
        "             'Corn_(maize)___Common_rust_':8,\n",
        "             'Corn_(maize)___Northern_Leaf_Blight':9,\n",
        "             'Corn_(maize)___healthy':10,\n",
        "             'Grape___Black_rot':11,\n",
        "             'Grape___Esca_(Black_Measles)':12,\n",
        "             'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)':13,\n",
        "             'Grape___healthy':14,\n",
        "             'Orange___Haunglongbing_(Citrus_greening)':15,\n",
        "             'Peach___Bacterial_spot':16,\n",
        "             'Peach___healthy':17,\n",
        "             'Pepper,_bell___Bacterial_spot':18,\n",
        "             'Pepper,_bell___healthy':19,\n",
        "             'Potato___Early_blight':20,\n",
        "             'Potato___Late_blight':21,\n",
        "             'Potato___healthy':22,\n",
        "             'Raspberry___healthy':23,\n",
        "             'Soybean___healthy':24,\n",
        "             'Squash___Powdery_mildew':25,\n",
        "             'Strawberry___Leaf_scorch':26,\n",
        "             'Strawberry___healthy':27,\n",
        "             'Tomato___Bacterial_spot':28,\n",
        "             'Tomato___Early_blight':29,\n",
        "             'Tomato___Late_blight':30,\n",
        "             'Tomato___Leaf_Mold':31,\n",
        "             'Tomato___Septoria_leaf_spot':32,\n",
        "             'Tomato___Spider_mites Two-spotted_spider_mite':33,\n",
        "             'Tomato___Target_Spot':34,\n",
        "             'Tomato___Tomato_Yellow_Leaf_Curl_Virus':35,\n",
        "             'Tomato___Tomato_mosaic_virus':36,\n",
        "             'Tomato___healthy':37,\n",
        "             \n",
        "             }\n",
        "img_data_list=[]  #an array containing all the images\n",
        "labels_list = []  #an array containing all the labels/classes"
      ],
      "metadata": {
        "id": "A-wuGNZzwbRl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are creating a nested for loop , the first one loops through the entire directory(I have selected the color folder as it had all the rgb images) and selects the 38 different datasets .The label is also added using the dictionary we made earlier.\n",
        "The second for loop runs through each label and reads each the image files using imread , resizes each image into the height and width we want , appends each image to the image array , the label is also appended to the label array\n",
        "\n",
        "While running the code the limit of 12GB RAM surpassed and I had to reduce the number of images in each label to 250"
      ],
      "metadata": {
        "id": "Lawis7O_L3ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\t\t\n",
        "for dataset in data_dir_list:\n",
        "\timg_list=os.listdir('/tmp/PlantVillage-Dataset-master/raw/color'+'/'+ dataset)\n",
        "\tprint ('Loading the images of dataset-'+'{}\\n'.format(dataset))\n",
        "\tlabel = labels_name[dataset]\n",
        "\tfor img in img_list[:250]:\n",
        "\t\tinput_img=cv2.imread('/tmp/PlantVillage-Dataset-master/raw/color' + '/'+ dataset + '/'+ img )\n",
        "\t\tinput_img_resize=cv2.resize(input_img,(128,128))\n",
        "\t\timg_data_list.append(input_img_resize)\n",
        "\t\tlabels_list.append(label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ggDnPQi31GIX",
        "outputId": "4c4d2491-fbea-40c6-f3e0-794c9862e5da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the images of dataset-Tomato___Early_blight\n",
            "\n",
            "Loading the images of dataset-Raspberry___healthy\n",
            "\n",
            "Loading the images of dataset-Tomato___Late_blight\n",
            "\n",
            "Loading the images of dataset-Potato___healthy\n",
            "\n",
            "Loading the images of dataset-Apple___healthy\n",
            "\n",
            "Loading the images of dataset-Strawberry___Leaf_scorch\n",
            "\n",
            "Loading the images of dataset-Peach___Bacterial_spot\n",
            "\n",
            "Loading the images of dataset-Potato___Late_blight\n",
            "\n",
            "Loading the images of dataset-Apple___Cedar_apple_rust\n",
            "\n",
            "Loading the images of dataset-Peach___healthy\n",
            "\n",
            "Loading the images of dataset-Tomato___Bacterial_spot\n",
            "\n",
            "Loading the images of dataset-Tomato___Septoria_leaf_spot\n",
            "\n",
            "Loading the images of dataset-Cherry_(including_sour)___Powdery_mildew\n",
            "\n",
            "Loading the images of dataset-Blueberry___healthy\n",
            "\n",
            "Loading the images of dataset-Cherry_(including_sour)___healthy\n",
            "\n",
            "Loading the images of dataset-Grape___healthy\n",
            "\n",
            "Loading the images of dataset-Corn_(maize)___healthy\n",
            "\n",
            "Loading the images of dataset-Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "\n",
            "Loading the images of dataset-Orange___Haunglongbing_(Citrus_greening)\n",
            "\n",
            "Loading the images of dataset-Strawberry___healthy\n",
            "\n",
            "Loading the images of dataset-Corn_(maize)___Northern_Leaf_Blight\n",
            "\n",
            "Loading the images of dataset-Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "\n",
            "Loading the images of dataset-Tomato___healthy\n",
            "\n",
            "Loading the images of dataset-Tomato___Target_Spot\n",
            "\n",
            "Loading the images of dataset-Soybean___healthy\n",
            "\n",
            "Loading the images of dataset-Tomato___Tomato_mosaic_virus\n",
            "\n",
            "Loading the images of dataset-Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "\n",
            "Loading the images of dataset-Apple___Apple_scab\n",
            "\n",
            "Loading the images of dataset-Apple___Black_rot\n",
            "\n",
            "Loading the images of dataset-Potato___Early_blight\n",
            "\n",
            "Loading the images of dataset-Pepper,_bell___healthy\n",
            "\n",
            "Loading the images of dataset-Grape___Black_rot\n",
            "\n",
            "Loading the images of dataset-Pepper,_bell___Bacterial_spot\n",
            "\n",
            "Loading the images of dataset-Tomato___Leaf_Mold\n",
            "\n",
            "Loading the images of dataset-Corn_(maize)___Common_rust_\n",
            "\n",
            "Loading the images of dataset-Squash___Powdery_mildew\n",
            "\n",
            "Loading the images of dataset-Grape___Esca_(Black_Measles)\n",
            "\n",
            "Loading the images of dataset-Tomato___Spider_mites Two-spotted_spider_mite\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "img_data now contains all the images in array form , we set the type of each element as float "
      ],
      "metadata": {
        "id": "l0urpBerM9Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data = np.array(img_data_list)\n",
        "img_data = img_data.astype('float32')\n"
      ],
      "metadata": {
        "id": "gcpc36FU6KFs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each value would be in a range of 0 to 255 which will take a lot of computation time so we will divide each value by 255 to make it in a range of 0 to 1 "
      ],
      "metadata": {
        "id": "8Gq2mATfNUMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_data /= 255  #normalizing the data so that the value is less than 1 -fast computation"
      ],
      "metadata": {
        "id": "ZyMz9e-O8vTt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check how many images are there"
      ],
      "metadata": {
        "id": "rRTL9gNvNjsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (img_data.shape)  #total 9000 images ,it was 50000 earlier but ram stopped owking to reduced it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4a2kXaav_CPs",
        "outputId": "4629119b-b5e9-418b-d0c4-1f90187e9e3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9402, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check how many images we have in each label"
      ],
      "metadata": {
        "id": "51ZmvcHDN8bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(labels_list)\n",
        "print(np.unique(labels,return_counts=True))  #shows that 250 images are taken from each class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y68D__rW_X12",
        "outputId": "2811b752-0402-450f-b9cc-07d79db8801e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 35, 36, 37]), array([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,\n",
            "       250, 250, 250, 250, 250, 250, 250, 250, 250, 152, 250, 250, 250,\n",
            "       250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use scikit learn to do a train test split\n",
        "The test size is 0.2 which is 20 percent of the data ,80 percent will be used for training"
      ],
      "metadata": {
        "id": "8q0-rQ0-OELu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "QsGZPf0i_7fL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "x,y = shuffle(img_data,Y, random_state=2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "eZI3LQpb_1d7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the shapes as it is very important for the X_train and y_train to have the same examples .\n",
        "We are using one hot encoding which basically means each element in the array will represent one label (38 elements here) and if the image belongs to a label the corresponding element is 1 the rest are 0s\n",
        "We can see that by printing the first 5 elements of y_train"
      ],
      "metadata": {
        "id": "bH1lOjsrObfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(y_train[:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "30lkqmJlAp4A",
        "outputId": "d11a943d-8ff0-4a91-80b6-3edca0669e93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7521, 128, 128, 3)\n",
            "(1881, 128, 128, 3)\n",
            "(7521, 38)\n",
            "(1881, 38)\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now begins the the most important part \n",
        "To make the model using CNN we will first import the needed libraries "
      ],
      "metadata": {
        "id": "NnCoVcwCPIkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n"
      ],
      "metadata": {
        "id": "xuvrJesfWTgp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use 3 layers for our model \n",
        "\n",
        "Input layer : We will perform the convolution operation first by using 32 filters each of the size 3x3 .The activation function we use will be ReLu ,it is the best for normalizing data. Max pooling basically reduces the input size and here we will take a stride of 2 \n",
        "\n",
        "Hideen layer: It is the same as input layer but it has more filters \n",
        "\n",
        "Output layer:We will flatten our output (make it 1D) and put it as an input to this layer .The final layer should have the same size as the number of classes .We will use softmax now as"
      ],
      "metadata": {
        "id": "oyANcfFhPbZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define the model\n",
        "# input_shape=img_data[0].shape\n",
        "# model = Sequential()\n",
        "\n",
        "# model.add(Convolution2D(32, 3,3,border_mode='same',input_shape=input_shape))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Convolution2D(32, 3, 3))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Convolution2D(64, 3, 3))\n",
        "# model.add(Activation('relu'))\n",
        "# #model.add(Convolution2D(64, 3, 3))\n",
        "# #model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(num_classes))\n",
        "# model.add(Activation('softmax'))\n",
        "\n",
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax'),\n",
        "    \n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "eRM9G2FUBE8J"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will compile all the layers .Categorical crossentropy is used as we have more than two categories"
      ],
      "metadata": {
        "id": "PZ4U7CKTQqIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gRsDgVlxXU0l"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking out how the shapes of the input and output will be in each layer"
      ],
      "metadata": {
        "id": "Jj5kqG0JQ1SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()\n",
        "cnn.get_config()\n",
        "cnn.layers[0].get_config()\n",
        "cnn.layers[0].input_shape\t\t\t\n",
        "cnn.layers[0].output_shape\t\t\t\n",
        "cnn.layers[0].get_weights()\n",
        "np.shape(cnn.layers[0].get_weights()[0])\n",
        "cnn.layers[0].trainable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BCmkgQeN97Cj",
        "outputId": "7e89b50a-0737-4fde-bf6d-45641ab0e46f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 63, 63, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 57600)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                3686464   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 38)                2470      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,708,326\n",
            "Trainable params: 3,708,326\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally training the model . It took around 30 mins for this to run.A higher batch size will take less time but the accuracy will be lower so went with 16"
      ],
      "metadata": {
        "id": "iIFAHt-kRBxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = cnn.fit(X_train, y_train, batch_size=16, epochs=10, verbose=1, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "keyjL86XXeAu",
        "outputId": "6bc591a7-38fd-480d-828a-2cee49d7fd16"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "471/471 [==============================] - 159s 337ms/step - loss: 2.3455 - accuracy: 0.3574 - val_loss: 1.5435 - val_accuracy: 0.5476\n",
            "Epoch 2/10\n",
            "471/471 [==============================] - 158s 336ms/step - loss: 1.0863 - accuracy: 0.6761 - val_loss: 1.1230 - val_accuracy: 0.6704\n",
            "Epoch 3/10\n",
            "471/471 [==============================] - 159s 337ms/step - loss: 0.5977 - accuracy: 0.8128 - val_loss: 1.0185 - val_accuracy: 0.7055\n",
            "Epoch 4/10\n",
            "471/471 [==============================] - 159s 337ms/step - loss: 0.2939 - accuracy: 0.9095 - val_loss: 1.1364 - val_accuracy: 0.7033\n",
            "Epoch 5/10\n",
            "471/471 [==============================] - 159s 337ms/step - loss: 0.1741 - accuracy: 0.9442 - val_loss: 1.1497 - val_accuracy: 0.7294\n",
            "Epoch 6/10\n",
            "471/471 [==============================] - 160s 339ms/step - loss: 0.1081 - accuracy: 0.9653 - val_loss: 1.4462 - val_accuracy: 0.7108\n",
            "Epoch 7/10\n",
            "471/471 [==============================] - 158s 336ms/step - loss: 0.0809 - accuracy: 0.9766 - val_loss: 1.5482 - val_accuracy: 0.7166\n",
            "Epoch 8/10\n",
            "471/471 [==============================] - 158s 335ms/step - loss: 0.0900 - accuracy: 0.9718 - val_loss: 1.5880 - val_accuracy: 0.6730\n",
            "Epoch 9/10\n",
            "471/471 [==============================] - 158s 336ms/step - loss: 0.0824 - accuracy: 0.9750 - val_loss: 2.1795 - val_accuracy: 0.6284\n",
            "Epoch 10/10\n",
            "471/471 [==============================] - 158s 335ms/step - loss: 0.0764 - accuracy: 0.9765 - val_loss: 1.8508 - val_accuracy: 0.6683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average accuracy is 66 percent "
      ],
      "metadata": {
        "id": "Pyp_SBVqRSAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r0Qc_Zn-FCHj",
        "outputId": "c4686cc6-ec05-4c47-aea6-5a0749ef59f9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 9s 157ms/step - loss: 1.8508 - accuracy: 0.6683\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8508288860321045, 0.6682615876197815]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will make the prediction and print the first 5 outputs "
      ],
      "metadata": {
        "id": "ybNfZuYYRapE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cnn.predict(X_test)\n",
        "y_pred[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "45HYYJCQFekG",
        "outputId": "619e3b51-b72d-4220-cbf7-cc954714a739"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.13544963e-19, 3.85957786e-13, 9.14536782e-21, 1.24451005e-11,\n",
              "        8.23121684e-16, 6.59421866e-12, 1.15202736e-10, 8.20853004e-20,\n",
              "        7.27910076e-27, 7.17235578e-32, 5.97415457e-30, 9.07640469e-08,\n",
              "        3.99202962e-11, 1.72791526e-09, 2.13200972e-17, 3.05697689e-09,\n",
              "        1.98940156e-10, 8.29694332e-13, 9.81666386e-01, 1.83332451e-02,\n",
              "        6.55827203e-15, 2.59780836e-10, 2.00308575e-10, 5.70309986e-08,\n",
              "        9.69793169e-12, 1.26097325e-18, 7.38118131e-14, 5.81349350e-17,\n",
              "        1.16180474e-18, 4.70884284e-14, 1.86352977e-07, 2.43182496e-09,\n",
              "        8.28678471e-18, 9.18475607e-09, 9.65010745e-15, 9.91380806e-13,\n",
              "        2.89829343e-16, 5.35553383e-19],\n",
              "       [2.30401126e-03, 2.53962384e-07, 3.45262725e-14, 5.68081362e-07,\n",
              "        2.44635459e-08, 8.44080574e-17, 9.65469232e-11, 1.86137790e-17,\n",
              "        4.97223097e-17, 2.93419730e-16, 1.01518608e-21, 7.56229389e-13,\n",
              "        3.86219790e-06, 1.42044044e-07, 3.13509496e-11, 5.03266578e-17,\n",
              "        1.88168451e-05, 1.40871773e-10, 3.24022898e-04, 1.00642748e-04,\n",
              "        8.93869071e-07, 3.49565162e-05, 5.27590544e-07, 3.47488304e-03,\n",
              "        1.65114606e-08, 1.12342185e-07, 1.21811228e-09, 2.07942410e-08,\n",
              "        2.87638294e-14, 4.57650032e-07, 3.87463433e-06, 9.93675530e-01,\n",
              "        5.63571302e-05, 8.02759890e-14, 7.29554611e-11, 7.32074384e-12,\n",
              "        8.69502560e-12, 8.83484663e-09],\n",
              "       [1.12199048e-02, 1.28528394e-04, 9.15017893e-07, 1.15533942e-06,\n",
              "        1.05094759e-10, 3.18747482e-07, 6.91287482e-07, 1.48200593e-06,\n",
              "        1.59742412e-12, 3.99654171e-10, 1.40212564e-11, 4.12226043e-04,\n",
              "        1.71115389e-03, 1.18836993e-03, 9.57567980e-09, 5.30380967e-05,\n",
              "        2.92352766e-01, 6.06642701e-08, 4.68710773e-02, 2.70052075e-01,\n",
              "        2.12336472e-05, 8.14718101e-03, 1.49800850e-03, 2.69135296e-01,\n",
              "        4.67620715e-08, 6.11534560e-05, 1.31559605e-03, 9.25597760e-06,\n",
              "        2.38057673e-05, 6.89398218e-03, 5.91794145e-04, 4.79874536e-02,\n",
              "        1.54148496e-04, 1.54488010e-03, 6.53806026e-04, 4.60504198e-05,\n",
              "        5.25726500e-06, 3.79173271e-02],\n",
              "       [1.32259351e-11, 2.72393976e-07, 7.91861225e-07, 8.13223622e-09,\n",
              "        1.62347177e-07, 8.03821080e-04, 9.94852006e-01, 7.94773598e-08,\n",
              "        2.26850511e-10, 1.28375316e-12, 2.57324492e-11, 1.30290689e-04,\n",
              "        1.73655430e-11, 2.01908335e-07, 4.80123958e-08, 1.18846674e-05,\n",
              "        2.08880010e-05, 2.23017036e-08, 1.03263210e-06, 5.42218640e-06,\n",
              "        2.01039654e-11, 1.92519849e-08, 7.01814107e-10, 1.43226409e-08,\n",
              "        2.51279952e-09, 3.35118528e-08, 6.18696161e-09, 2.09761417e-08,\n",
              "        1.15404764e-09, 9.19533161e-09, 3.02977534e-03, 2.64097423e-07,\n",
              "        1.14289857e-03, 3.76472437e-10, 3.36566365e-11, 1.20997043e-07,\n",
              "        2.53840959e-11, 1.62990422e-12],\n",
              "       [2.04774756e-06, 1.47495091e-12, 1.50161110e-08, 4.77208095e-09,\n",
              "        5.10896950e-11, 5.37147887e-12, 1.08240621e-11, 7.62730428e-13,\n",
              "        4.64501632e-10, 1.06763097e-11, 5.93723840e-17, 2.46649784e-10,\n",
              "        5.31577982e-08, 2.38907205e-09, 4.79880248e-14, 4.86631957e-10,\n",
              "        4.98206705e-01, 3.08888644e-07, 1.03487590e-04, 3.28234706e-09,\n",
              "        2.15107463e-07, 1.60276086e-05, 3.41030677e-14, 7.72170416e-09,\n",
              "        2.55685620e-12, 4.32404763e-12, 6.17718054e-09, 1.15798365e-14,\n",
              "        1.12586953e-08, 2.51032901e-03, 4.99597401e-04, 4.97409135e-01,\n",
              "        1.25099625e-03, 1.40365818e-11, 5.52608848e-13, 1.09477435e-06,\n",
              "        3.09390842e-08, 9.52861835e-12]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label with the highest value will be the predicted one, using argmax we get the following labels for the first 5 examples"
      ],
      "metadata": {
        "id": "UTuCbgPuRm37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_classes = [np.argmax(element) for element in y_pred]\n",
        "y_classes[:5] #the classes we get as prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UGA-daUjF1RI",
        "outputId": "b6a4ae91-5a18-466a-caae-259293df22d0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18, 31, 16, 6, 16]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the actual labels of the examples .These are difficult to view in one hot encoding "
      ],
      "metadata": {
        "id": "9kdWyBk8R_m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oHsdCDy-F9mb",
        "outputId": "7dc00d15-ca08-46e1-b0bb-3a8c8039b8f9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 out of 5 of the predictions are accurate :))"
      ],
      "metadata": {
        "id": "cixFpsZySO68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual_classes=[np.argmax(element) for element in y_test]\n",
        "print(y_actual_classes[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1RKxHdhScK4",
        "outputId": "9f62dc3d-0568-49de-9a0e-75eb21eaee27"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18, 32, 16, 6, 16]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "plant_disease_prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPil/TAXrUpJr4Re9ZmDXsF",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}